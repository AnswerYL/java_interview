#### 线程和进程的区别?

- 进程是正在运行程序的实例，进程中包含线程，每个线程执行不同的任务

- 不同的进程使用不同的内存空间，在当前进程下所有线程可以共享内存空间

- 线程更轻量，线程上下文切换成本一般要比进程低（上下文切换是指从一个线程切换到另一个线程）

#### 并发和并行有什么区别?

并发是同一时间应对多件事情的能力（一个人同一时间内，打篮球、踢足球、学习...，这些只能轮流做就叫做并发）

并行是同一时间做多件事情的能力（两个人同一时间内，一个打篮球、一个踢足球...，这种两个人做两件事就叫并行）

现在都是多核CPU，在多核CPU下

- 并发是多线程轮流使用一个或多个CPU

- 并行是4个CPU同一时间执行4个线程

#### 创建线程的方式有哪些？（重点）

- 继承Thread类

- 实现Runable接口

- 实现Callable接口

- 线程池创建线程

#### Runable和Callable有什么区别？

Runable的run方法没有返回值

Callable的call方法有返回值，需要结合FutureTask获取返回值

Callable的call方法可以抛出异常，Runable的run方法异常只能通过try-catch捕捉处理

#### run()和start()有什么区别？

执行run方法只是执行了一个普通方法，没有开启线程，可以多次执行

执行start方法是开启一个线程用来执行run方法，只能执行一次

#### 线程中包含哪些状态，状态之间如何变化？（重点）

- NEW：新建未启动线程状态，Thread t = new Thread();

- RUNABLE：可运行线程状态，t.start()

- BLOCKED：线程阻塞状态，t未得到锁

- WAITING：等待线程状态，t.wait()，没有notify()唤醒

- TIMED_WAITING：指定等待时间的等待线程状态，Thread.sleep(500)

- TERMINATED：已终止线程状态（线程执行完成）

![](/Users/liuyang/Documents/Ai学习/java面试/线程状态变化流程图.png)

#### T1,T2,T3三个线程按照顺序执行？

- join()方法，在线程中使用，等待前一个线程执行完，才开始执行

- join()方法，在主线程中使用

- 使用单线程池

- 使用CountDownLatch

- 使用CompletableFuture（按流程顺序运行）

#### 如何停止正在运行的线程？

- 使用thread的stop方法（不推荐，官方已停用）

- 使用interrupt中断线程（但并不能确定线程停止）
  
  - 中断阻塞状态的线程（wait、join、sleep）等，线程会抛出InterruptedException异常并且打断阻塞，线程继续向下执行
  
  - 中断正常的线程，可以根据中断状态判断是否退出线程

#### synchronized关键字的底层原理

- synchronized【对象锁】采用互斥方式让同一时刻至多只有一个线程持有【对象锁】

- 底层由monitor【监视器】实现，monitor是JVM级别的对象（c++实现），线程获得锁需要对象（锁）关联monitor

- monitor内部三个属性：owner，entrylist，waitset

- 其中owner是关联持有锁的线程，并且只能关联一个线程；entrylist关联的是处于阻塞（Blocked）状态的线程；waitset关联的是处于Waitting状态的线程

#### synchronized的锁升级（重点）

**轻量级锁与偏向锁区别**：轻量级锁每次退出同步块都需要释放锁，而偏向锁是在竞争发生时才释放锁

Lock Record：包含两部分；lock record地址、Object reference

- 偏向锁
  
  - 一段很长的时间内都只被一个线程持有锁，可以使用偏向锁。
  
  - 在第一次获取锁时，会有一个CAS操作，将该线程ID同步到锁对象的Markword中。
  
  - 之后该线程再获取锁，只需要判断Markword中是否是该线程ID即可，而不是重新进行CAS操作

- 轻量级锁
  
  - 轻量级锁：多线程竞争，但是任意时刻最多只有一个线程竞争，即不存在竞争太过激烈的情况，也就没有线程阻塞。
  
  - **主要目的**：为了在线程近乎交替执行同步块时提高性能，通过**CAS减少**重量级锁使用操作系统互斥量产生的性能消耗，即**先自旋再阻塞**，本质就是**自旋锁CAS思想**
  
  - **升级时机**：当关闭偏向锁功能或多线程竞争偏向锁会导致偏向锁升级为轻量级锁
  
  - 轻量级锁的使用场景：如果一个对象虽然有多线程要加锁，但加锁的时间是错开的（即没有竞争），那么可以使用轻量级锁来优化（将**线程栈帧中的锁记录Lock Record**当做**轻量级锁**）。
  
  - 轻量级锁对使用者是透明的，即语法仍然是 synchronized

- 重量级锁

![在这里插入图片描述](https://img-blog.csdnimg.cn/b72597c3415745108fdd021af211e97f.png)

#### JMM模型

**JMM模型，定义了共享内存中多线程程序的读写规范**，通过这些规范保证数据正确

- JMM将内存分为两块，一块是线程私有的工作区域(CPU缓存)，一块是线程公有的共享区域（主内存）

- 线程与线程之间是相互隔离的，线程和线程之间的数据交互需要通过主内存

- 操作
  
  - read 读取：作用于主内存将共享变量从主内存传送到线程的工作内存中。
  
  - load 载入：作用于工作内存，把 read 读取的值放到工作内存中的副本变量中。
  
  - store 存储：作用于工作内存，把工作内存中的变量传送到主内存中。
  
  - write 写入：作用于主内存，把从工作内存中 store 传送过来的值写到主内存的变量中。
  
  - use 使用：作用于工作内存，把工作内存的值传递给执行引擎，当虚拟机遇到一个需要使用这个变量的指令时，就会执行这个动作。
  
  - assign 赋值：作用于工作内存，把执行引擎获取到的值赋值给工作内存中的变量，当虚拟机栈遇到给变量赋值的指令时，就执行此操作。
  
  - lock锁定： 作用于主内存，把变量标记为线程独占状态。
  
  - unlock解锁： 作用于主内存，它将释放独占状态。

#### Volatile的理解

- 保证线程间的可见性
  
  用volatile修饰的共享变量，能够防止编译器等优化，可以让一个线程的修改对另一个线程可见

- 禁止指令重排序
  
  用valotile修饰的共享变量，会在读写共享变量时，加入不同的屏障，阻止其他读写操作越过屏障，从而达到阻止指令重排

#### 什么是AQS？（重点）

- 多线程中的抽象队列同步器，是一种由Java本身实现的锁机制，作为一个基础框架使用，例如ReentrantLock，Semaphare，CountDownLatch都是基于AQS实现的

- AQS内部维护着一个先进先出的双向队列，队列中存储排队的线程

- AQS内部还有一个属性state，这个state就相当于一个资源，默认为0（无锁状态），如果有线程抢到锁则将state通过CAS修改为1（有锁）,保证原子性，其余线程进入队列  

- 支持公平锁和非公平锁
  
  - 新来的线程和队列中线程竞争state资源，是非公平锁
  
  - 新来的线程直接进入队列队尾，先有队列中head线程获取资源，是公平锁

- 主要属性
  
  ```java
      // 内部虚拟的双向队列的头尾结点
      private transient volatile Node head;
      private transient volatile Node tail;
      // 资源，使用volatile保证可见性（CAS修改）
      private volatile int state;
  ```

- 核心方法
  
  - **tryAcquire**：**尝试获取锁**，获取成功则设置锁状态并返回true，否则返回false。
  
  - **addWaiter：入队**，即将当前线程加入到CLH同步队列尾部。
  
  - **acquireQueued**：当前线程会根据公平性原则来进行阻塞等待（自旋）,直到获取锁为止；并且返回当前线程在等待过程中有没有中断过。
  
  ![](https://img-blog.csdnimg.cn/img_convert/673222cbe6ede7612b7a3a303a2c5f0c.png)

#### ReentrantLock（可重入锁）的实现原理

##### 特性：

- 可中断

- 可以设置超时时间

- 可以设置公平锁

- 支持多个条件变量

- 与synchronized一样，可以重入

#### 实现原理：

- 底层使用CAS+AQS队列实现

- 新来的线程通过CAS修改state状态
  
  - 成功则为1，让exclusiveOwnerThread属性指向当前线程
  
  - 修改失败，线程进入双向队列中等待，head指向双向队列头部，tial指向队列尾部

- 当exclusiveOwnerThread属性为空时，则会唤醒队列同步队列中head节点后的第一个线程节点

- 公平锁体现在队列中的线程先后顺序获取锁，非公平锁体现在不在队列中的线程同样可以竞争锁

- 同一线程未释放再获得锁，每次重入state都会加1

#### Lock和Synchronized有什么区别

- 语法层面
  
  - Synchronized是关键字，源码在jvm中，由c++实现
  
  - Lock是接口，源码在jdk中，由java实现
  
  - 使用Synchronized时，退出同步代码块，锁自动释放；使用Lock时，锁需要调用unlock方法释放

- 功能层面
  
  - 二者都属于悲观锁，都具备基本的互斥、同步、重入功能
  
  - Lock提供了很多Synchronized不具备的功能，例如公平锁、可打断、可超时、多条件变量
  
  - Lock有适合不同场景的实现，如ReentrantLock、ReentrantReadWriteLock（读写锁）

- 性能层面
  
  - 没有大量竞争时，Synchronized锁优化后，如偏向锁、轻量级锁，性能也还行
  
  - 竞争激烈时，Lock的实现通畅会提供更好的性能

#### wait()和await()的区别

1. **`wait()`**：
   
   - `wait()` 是 Java 中的一个方法，通常与 `notify()` 和 `notifyAll()` 一起用于实现线程之间的协作。它是 `Object` 类的一个方法，可以在任何对象上调用。
   - `wait()` 用于让一个线程等待，直到其他线程通过调用相同对象上的 `notify()` 或 `notifyAll()` 来唤醒等待的线程。
   - `wait()` 必须在 `synchronized` 块或方法内部调用，以释放对象的锁。

2. **`await()`**：
   
   - `await()` 是与 Java 并发包（`java.util.concurrent`）中的条件（Condition）对象一起使用的，通常与 `ReentrantLock` 或 `Semaphore` 等同步工具一起使用。
   - `await()` 用于让线程等待某个条件满足，然后继续执行。它通常与 `signal()` 或 `signalAll()` 方法一起使用，这些方法用于通知等待的线程。
   - `await()` 不需要在同步块内调用，因为它通常与 `ReentrantLock` 或其他同步工具一起使用，并且自己管理了同步。

#### 死锁的条件

- **互斥条件**：一个资源每次只能被一个进程使用

- **请求与保持条件**：一个进程因请求资源而阻塞时，对已获得的资源保持不放

- **不可剥夺条件**：进程已获得的资源，在末使用完之前，不能强行剥夺

- **循环等待条件**：若干进程之间形成一种头尾相接的循环等待资源关系

#### 如何进行死锁中诊断

- 出现死锁：使用jdk自带的jps和jstack

- jps：输出JVM中运行的进程状态

- jstack：查看java进程中线程的堆栈信息，查看日志，检查是否有死锁信息，排查解决

- 可视化工具jconsole，VisualVM也可以检查死锁问题

#### ConcurrentHashMap（重点）

- 底层数据结构
  
  - JDK1.7：分段数组（segment）+HashMap（数组+链表）实现
  
  - JDK1.8+：采用和普通HashMap同样的数据结构，数组+链表|红黑树 实现

- 加锁方式
  
  - JDK1.7：采用锁住segment分段（无法扩容），底层用ReentrantLock
  
  - JDK1.8+：采用CAS添加新节点，采用synchronized锁定链表或者红黑树的首节点，相对segment分段锁粒度更细，性能更好

#### 导致并发程序出现问题的根本原因是什么？

##### 三大特性：

- 原子性：一个线程在cpu中操作，不可暂停、不可中断、要不执行完成要不不执行
  
  - synchronized：同步加锁
  
  - JUC里面的lock：ReentrantLock、ReentrantReadWriteLock等

- 可见性：一个线程对共享变量的修改对另一个线程可见
  
  - volatile
  
  - 加锁

- 有序性：指令重排，处理器为了提高运行效率、在不影响代码流程的情况下，有可能会打乱代码顺序，不保证执行顺序和编写代码顺序一致
  
  - volatile

#### 线程池的核心参数（重点）

- **int corePoolSize**：核心线程数
  
  高并发、任务执行时间短，设置核心线程数（N+1）,减少线程上下文切换
  
  并发不高、任务执行时间长
  
  - IO密集型任务
    
    - 文件读写、DB读写、网络请求等
    
    - 设置核心线程数大小为2N+1（N为cpu核数）
    
    - 文件操作占用cpu较少，线程数设置多一些
  
  - CPU密集型任务
    
    - 计算型代码、Bitmap转换、Json转换等
    
    - 设置核心线程数大小为N+1（N为cpu核数）
    
    - 计算大量占用CPU，减少线程切换，增加效率

- **int maximumPoolSize**：最大线程数（核心线程数+临时线程数）

- **long keepAliveTime**：生存时间--临时线程的生存时间、生存时间内没有新任务，释放临时线程

- **TimeUnit unit**：临时线程生存时间的单位，如毫秒、秒、分钟等

- **BlockingQueue<Runnable> workQueue**：当没有空闲的核心线程时，新任务会加入到此阻塞队列开始等待，队列满会创建临时线程执行任务

- **ThreadFactory threadFactory**：线程工厂-可以定制线程对象（核心线程或临时线程）的创建，例如设置线程名称、是否是守护线程等

- **RejectedExecutionHandler handler**：拒绝策略-当所有线程（核心线程和临时线程）都在忙，workQueue也满了，会触发拒绝策略

#### 线程池的执行原理（重点）

![](/Users/liuyang/Library/Application%20Support/marktext/images/2023-10-30-17-23-29-image.png)

**拒绝策略**：

- AbortPolicy()，直接抛出异常，默认策略

- DiscardPolicy()，直接丢弃任务

- DiscardOldestPolicy()，丢弃阻塞队列最前的任务，并将当前任务插入到队列尾部

- CallerRunsPolicy()，用调用者所在的线程执行任务

#### 线程池中有哪些常见的阻塞队列？（重点）

- **ArrayBlockingQueue**：基于数组，有界阻塞队列，FIFO（先进先出）

- **LinkedBlockingQueue**：基于单向链表，有界阻塞队列，FIFO

- **DelayQueue**：一个有优先级的队列，可以保证每次出队的任务都是优先级最高的

- **SynchronousQueue**：不存储元素的阻塞队列，每插入一个任务必须等待一个移出操作

| LinkedBlockingQueue             | ArrayBlockingQueue    |
|:-------------------------------:|:---------------------:|
| 无界，但默认长度为Integer.MAX_VALUE、支持有界 | 强制有界                  |
| 底层是链表                           | 底层是数组                 |
| 是懒惰的，创建节点时添加数据                  | 提前初始化Node数组           |
| 入队会生成新Node                      | Node是需要提前创建好          |
| 两把锁（head、tail），入队和出队不同的锁，效率较高   | 一把锁，  锁住整个数组，入队出队效率较低 |
| ReentrantLock                   | ReentrantLock         |

#### 线程池种类有哪些？（重点）

- **newFixedThreadPool(int nThreads)**：创建固定线程池
  
  - 核心线程数和最大线程数：nThreads，没有临时线程
  
  - 阻塞队列是LinkedBlockingQueue，容量为默认的Integer.MAX_VALUE
  
  - 适用场景：任务量已知，相对耗时的任务

- **newSingleThreadExecutor()**：创建只有一个核心线程的线程池，保证任务按指定顺序（FIFO）执行
  
  - 核心线程数和最大线程数：1，没有临时线程
  
  - 阻塞队列是LinkedBlockingQueue，容量为默认的Integer.MAX_VALUE
  
  - 适用场景：按照顺序执行的任务

- **newCachedThreadPool()**：创建可缓存线程池
  
  - 核心线程数：0，最大线程数：Integer.MAX_VALUE
  
  - 临时线程生存时间60秒
  
  - 阻塞队列为SynchronousQueue，不存储任务，新插入一个必须等待一个移出
  
  - 适用场景：任务数比较密集，但每个任务执行时间较短

- **newScheduledThreadPool(int corePoolSize)**：创建定时及周期执行任务的线程池
  
  - 核心线程数：corePoolSize，最大线程数：Integer.MAX_VALUE，临时线程数：Integer.MAX_VALUE-corePoolSize
  
  - 临时线程存活时间：0
  
  - 阻塞队列DelayedWorkQueue：

#### 为什么不建议用Executors创建线程池？

- 固定大小线程池和单一线程池，阻塞队列都是LinkedBlockingQueue，允许请求的队列长度为Integer.MAX_VALUE，可能会堆积大量的请求，导致OOM

- 可缓存线程池，允许创建的线程数量为Integer.MAX_VALUE，可能会创建大量的线程，从而导致OOM

#### 使用场景（重点）

- CountDownLatch + 线程池，实现批量大数据导入

- Future+线程池，实现微服务数据汇总（报表汇总），优化接口时间

- 异步调用，实现邮件发送、搜索记录保存

#### 如何控制某个方法并发访问线程的数量？

使用多线程JUC包里面的Semaphore信号量，在并发的情况下，可以控制访问数量

1. 创建Semaphore对象，给定容量

2. acquire()，获取许可，这时信号量容量-1，直到容量耗完

3. 执行完后，release()释放信号量，信号量容量+1

4. 信号量不为0时，才可以获取许可成功，其余线程等待

#### ThreadLocal的理解

1. 可以实现**资源对象**的线程隔离，让每个线程各用各的线程对象，避免争用引发的线程安全问题

2. 同时实现了线程内的资源共享

3. 每个线程内都维护了一个ThreadLocalMap类型的成员变量，用来存储资源对象
   
   1. 调用set方法就是以ThreadLocal自己作为key，资源对象为value，放入当前线程的ThreadLocalMap集合中，赋值给线程的threadLocals
   
   2. 调用get方法，还是以ThreadLocal自己作为key，到当前线程中查找关联的资源值
   
   3. 调用remove方法，还是以ThreadLocal自己作为key，到当前线程中移出关联的资源值

#### ThreadLocal内存泄露问题

- ThreadLocalMap中Entry是继承WeakReference(弱引用)，其中Entry中的key就是弱引用，但是value值是强引用

- 导致key会被GC回收，但value值却不会，可能会导致内存泄露

- 建议主动remove释放key，value
