## SpringCloud

**注册中心（Eureka，nacos）、负载均衡（Ribbon）、远程调用（Feign）、服务熔断（Hystris，Sentinel）、网关（Zuul、Gateway）**

### 服务注册

#### 服务注册和发现是什么意思？如何实现服务注册发现？

- 服务注册：服务提供者将自己的信息注册到Nacos，有Nacos保存信息，比如服务名称、ip、端口等

- 服务发现：服务消费者向Nacos拉取服务列表信息到本地，如果服务列表为多个，则消费者使用负载均衡算法，选择一个调用

- 服务监控：提供者会每隔30s向注册中心发送心跳，报告健康状态，如果90s或自定义时间没收到心跳，从服务列表中剔除

#### Nacos与Eureka的区别

- 共同点
  
  - 都支持服务注册和服务拉取
  
  - 都支持服务提供者心跳方式做健康检测

- 不同点
  
  - Nacos可以自定义临时实例和非临时实例（服务提供者）；临时实例采用心跳检测、非临时实例则有注册中心主动检测提供者状态
  
  - 临时实例心跳不通则会剔除、非临时实例则不会
  
  - 服务消费者除了从Nacos拉取服务外，在服务列表变更时，Nacos会主动推送新的服务列表，列表数据更新及时
  
  - Nacos和Eureka默认采用AP（高可用 ）模式，但Nacos有非临时实例时则是CP（强一致）模式

- Nacos还支持配置中心，eureka只是注册中心

### 负载均衡

#### 项目负载均衡是如何实现的？

微服务的负载均衡主要使用一个Ribbon组件、比如我们使用Feign远程调用的过程中、底层的负载均衡就是Ribbon

#### Ribbon负载均衡策略有哪些？

- **RoundRobinRule：轮询服务列表选择服务实例**

- **WeightedResponseTimeRule：按照权重来选择服务实例，响应时间越长，权重越小**

- **RandomRule：随机选择一个可用的服务实例**

- BestAvailableRule：忽略那些短路的服务实例，并选择并发数较低的服务器

- RetryRule：重试机制的选择（若请求失败，每隔一段时间重试）

- AvailabilityFilteringRule：可用性敏感策略，先过滤非健康的，再选择连接数较少的

- **ZoneAvoidanceRule（默认）：区域敏感策略，以区域可用的服务实例为基础进行服务实例选择。适用于服务实例在多地区或多机房部署，服务在同一Zone内进行轮询调用**

#### 自定义轮询策略

自己创建类实现IRule接口，然后通过配置类或者配置文件配置即可，配置方式有两种：

```java
// 全局生效，该消费者所有的远程调用负载均衡都采用这个策略
@Bean
public IRule cuntomRule(){
    return new CustomRule();
}
```

```yaml
# 局部生效、只针对配置的服务
sersevice:
    ribbon:
        NFLoadBalancerRuleClassName:com.xxx.CustomRule # 自定义均衡策略
```

### 熔断、降级

#### 什么是服务雪崩，怎么解决？

- 服务雪崩：微服务调用链中由于一个服务失败且一直未响应，导致整个调用链路都失败的情形

- 服务降级（针对微服务中部分接口）：服务自我保护的一种方式，当服务失败未响应时，返回降级后的信息，保证链路畅通。**一般在实际开发中与Feign接口整合，编写降级逻辑**

- 服务熔断（针对整个微服务）：默认是关闭状态，当**检测到10s内请求失败率超过50%**，就开启熔断，不在请求该服务实例，之后**每隔5s会重新尝试请求**，如果依然不能成功继续熔断，若服务修复则关闭熔断，恢复正常请求

### 监控

#### 微服务是怎么监控的？

我们采用的是skywalking进行监控

1. skywalking可以监控微服务，接口，物理实例的一些状态。在压测过程中及时发现问题（如服务或接口比较慢），针对问题进行分析和优化、解决。

2. 可以设置一些告警规则，上线后项目告警可以及时通知相关负责人，尽快排查问题进行解决。

## 业务相关

### 限流

#### 为什么要做限流？怎么做？

- 并发比较大（突发流量）

- 防止用户恶意刷接口

我们当时做了一个活动，定时发送优惠券，QPS会达到2000，平时10-50之间，为了应对突发流量，做的限流

- 正常情况下，根据测试时的压测结果，QPS达到1000系统正常，1000以上会导致系统反应慢，有可能会出现崩溃

Nginx限流

- 控制速率（突发流量）：漏桶算法；突然大量请求，进过一个'桶'，这个桶有固定的大小，然后按照一定速率将请求放出进行处理，当桶满时让请求等待或者抛弃

- 控制并发连接数：设置固定的连接

网关限流

- 在Gateway中支持局部过滤器RequestRateLimiter来做限流，使用令牌桶算法，可以根据ip或路径进行限流，设置每秒令牌生成速度和令牌桶总容量

- 令牌桶算法：突然大量请求过来，都要去令牌桶申请令牌，得到令牌的请求可以继续访问，未得到的将会阻塞或者抛弃

漏桶算法与令牌桶算法的区别

漏桶算法每秒固定释放请求数量，比较稳定；而令牌桶算法在之前令牌未被消耗的情况下会储存在令牌桶中，下次大量请求来时可能会一次释放同总容量一样的请求，不稳定

### 分布式事务

#### 解决分布式事务的思想和模型

- 最终一致思想：各分支事务分别执行并提交，如果有事务失败，再想办法恢复数据（AP）

- 强一致思想：各分支事务执行完业务部不提交，等待彼此结果，再统一提交或回滚（CP）

#### 采用哪种分布式事务解决方案？

- Seata框架（XA,AT,TCC）
  
  - Seata事务管理中的三个重要角色：
    
    -  TC-事务协调者：维护全局和分支事务的状态，协调全局事务提交或回滚
    
    - TM-事务管理器：定义全局事务的范围，通知TC开始全局事务、提交或回滚全局事务
    
    - RM-资源管理器：管理分支事务处理的资源，与TC交谈以注册、报告分支事务状态，并驱动分支事务提交或回滚
  
  - XA模式（CP），需要互相等待各个事务提交，可以保证强一致性，性能差；银行业务
  
  - AT模式（AP），底层使用undo log实现，性能好；互联网业务
  
  - TCC模式（AP），性能较好，不过需要人工编码实现；银行业务

- MQ分布式事务
  
  在A服务写数据时，需要在同一个事务内发送消息到另外一个事务，异步，性能最好；互联网业务

#### 分布式服务接口幂等性如何设计？

幂等：多次调用方法或接口不会改变业务状态，可以保证重复调用的结果和单次调用结果一致；如订单接口，点击多次和点击一次效果一样，只生产一份订单而不会生成多份。

幂等的场景：

- 用户重复点击（网络波动）

- MQ消息重复

- 应用使用失败或超时重试机制

接口幂等

- get和delete（根据唯一值删除）请求，天然幂等

- post请求，新增操作，不幂等

- put请求，修改操作，确定值更新幂等，增量更新不幂等

幂等解决办法

- 数据库唯一索引：新增数据时，添加唯一索引字段，保证数据幂等

- token+redis：新增、修改操作；性能较好
  
  - 客户端第一次请求，服务端生成token并保存在redis，返回给客户端
  
  - 客户端第二次请求，带token请求业务接口，验证token是否存在，存在则处理业务并删除token，不存在则返回

- 分布式锁：新增、修改操作；性能较低
  
  - 通过redission获得分布式锁，若得到锁继续操作，未得到锁快速失败，防止其他请求阻塞
  
  - 操作完成释放锁

#### 项目中使用了什么分布式任务调度？

xxl-job解决的问题

- 解决集群任务的重复执行问题

- cron表达式定义灵活

- 定时任务失败了，重试和统计

- 任务量大，分片执行

xxl-job路由策略有哪些？

- 轮询

- 故障转移：按照顺序依次进行心跳检测，第一个心跳检测成功的机器定为目标执行器并发起调度

- 分片广播：广播触发对应集群中的所有机器执行一次任务，同时系统自动传递分片参数，可根据分片参数开发分片任务

xxl-job任务执行失败怎么解决？

- 故障转移+失败重试，查看日志分析-->邮件告警

#### 如果有大数据量的任务同时都需要执行，怎么解决？

执行器集群部署时，任务路由策略选择分片广播情况下，一次任务调度将会广播出发对应集群中所有执行器执行一次任务。

## 消息中间件

- 异步发送（验证码、短信、邮件....）

- MySQL和Redis、ES之间的数据同步

- 分布式事务

- 削峰填谷

- ....

### RabbitMQ

#### 如何保证消息不丢失？

- 开启生产者确认机制，确保生产者的消息能到达队列

- 开启持久化功能，确保消息未消费前，在队列中不会消失

- 开启消费者确认机制为auto，由spring确认消息处理成功后返回ack

- 开启消费者失败重试机制，多次失败将消息投递到异常交换机，由人工处理

#### 重复消费问题如何解决？

每条消息设置一个唯一的标识id，在消费前可以去数据库查询该id是否存在

#### RabbitMQ中死信交换机？（延时队列有了解吗？）

消息超时未消费就会变成死信（死信其他情况：消息消费失败，队列满了最早的信息）

延时队列：进入队列的消息会被延时消费

场景：超时订单，限时优惠，定时发布...

延时队列实现：死信交换机+TTL（消息存活时间）

#### 消息堆积问题如何解决？

如果生产者发送消息的速度超过消费者处理消息的速度，就会产生消息堆积，直到队列存储信息达到上限，队列中最早的消息就会成为死信，可能会被丢弃，这就是消息堆积问题

解决三种思路：

- 增加更多的消费者，提高消费速度

- 在消费者内开启线程池加快消费者处理速度

- 扩大队列容积，提高堆积上限

#### RabbitMQ高可用机制

使用集群来保证高可用

- 普通集群
  
  - 会在集群的各个节点共享部分数据，包括交换机、队列元信息（引用信息）。不包含队列中的信息
  
  - 当访问某集群节点时，如果队列不在该节点，会从数据节点传递到当前节点
  
  - 队列所在节点宕机，队列中的消息也会消失

- **镜像集群**（主从模式）
  
  - 交换机、队列、队列中的消息会在各个MQ镜像节点之间同步备份
  
  - 创建队列的节点被称为主节点，备份到的其他节点被称为镜像节点
  
  - 一个队列的主节点肯能是其他队列的镜像节点
  
  - 所有操作都是主节点完成，然后同步给镜像节点
  
  - 主节点宕机后，镜像节点会称为新的主节点

- 仲裁队列（3.8版本后才有的新功能，替代镜像集群）
  
  - 与镜像队列一样，都是主从模式，支持主从数据同步
  
  - 使用非常简单，没有复杂的配置
  
  - 主从同步基于Raft协议，强一致

### Kafka

#### 保证消息不丢失?

需要从三个层面去解决问题：

- 生产者发送消息到broker丢失
  
  - 设置异步发送，发送失败使用回调进行记录或重发
  
  - 失败重试，可以设置重试次数

- 消息在broker中丢失
  
  - 发送确认acks，选择all，让所有的副本都参与保存数据后确认

- 消费者从broker接收消息丢失
  
  - 关闭自动提交偏移量，开启手动提交偏移量
  
  - 提交方式，最好是同步+异步

#### 消息重复消费的问题

- 关闭自动提交偏移量，开启手动提交偏移量

- 提交方式，最好是同步+异步

- 幂等方案

#### 消息消费的顺序性？

问题原因：

一个topic的数据可能存储在不同的分区中，每个分区都有一个按照顺序存储的偏移量，如果消费者关联多个分区不能保证顺序性

解决方案：

- 发送消息时指定分区号

- 发送消息时按照相同的业务设置相同的key

#### 高可用机制

- 集群模式
  
  - 一个kafka集群有多个broker实例组成，即使某一个broker宕机，也不耽误其他broker提供服务

- 分区备份（复制）机制
  
  - 一个topic有多个分区，每个分区有多个副本，有一个leader，其余都是follower，副本存储在不同的broker中
  
  - 所有分区副本内容都是相同的，如果leader发生故障，会自动将一个follower提升为leader，保证了系统的容错性、高可用性

#### 分区备份（复制）机制的ISR

ISR（in-sync replica）需要同步复制保存的follower

分区副本分为两类，一个是ISR，与leader同步保存数据；另一个是普通副本，是异步同步数据

当leader宕机，会优先从ISR副本列表中选择一个作为leader     

#### 数据清理机制

- 文件存储机制
  
  - topic的数据存储在分区上，分区如果文件过大会分段存储segment
  
  - 每个分段都在磁盘上以索引（xxxx.index）和日志文件（xxxx.log）的形式存储，xxxx是以偏移量来命名
  
  - 分段的好处是，第一能够减少单个文件内容的大小，查找数据方便，第二就是方便进行日志清理

- 数据清理机制
  
  - 根据消息保留时间，当消息保存时间超过指定时间，就会触发清理，默认是168小时（7天）
  
  - 根据topic存储的数据大小，当topic所占的日志文件大小大于一定的阈值，则开始删除最久的消息。（默认关闭，需手动开启）

#### 高性能设计

- **消息分区：不受单台服务器限制，可以不受限制处理更多的数据**

- **顺序读写：磁盘顺序读写，提升读写效率**

- **页缓存：把磁盘中的数据缓存到内存中，把对磁盘的访问变为对内存的访问**

- **零拷贝：减少上下文切换及数据拷贝**（将消息从磁盘拷贝到内核空间后，再拷贝给网卡，通过网络发送给消费者，减少拷贝次数）

- 消息压缩：减少磁盘IO和网络IO

- 分批发送：将消息打包批量发送，减少网络开销


